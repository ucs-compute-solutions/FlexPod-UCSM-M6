---
# Role variables as per NetApp's prescriptive guidance
# This can be overridden by a var-file.yml at the command line
# User's input variables

##################################################################################################################################################
# Cluster specific variables
##################################################################################################################################################

#Name of the ONTAP Cluster
cluster_name: FAA-4Node

#Location of the ONTAP Cluster
cluster_location: RTP-Lab1-F14

#Cluster management LIF already exists (pre-requisite), so note down name of cluster management LIF and enter below.
cluster_mgmt_interface: cluster_mgmt

#List the ONTAP Licenses for the different features that you need
ontap_license:
  - <License key for feature 1>
  - <License key for feature 2>
  - <License key for feature 3>

#Details for configuring NetApp AutoSupport
autosupport_vars:
  mail_hosts: "mailhost"
  noteto: "admin@netapp.com"
  proxy_url: #Optional: If authentication is used, use format: "username:password@host:port"
  from_address: "ontap_cluster@netapp.com"
  to_addresses: admin1@netapp.com,admin2@netapp.com

#SNMP related variables
enable_snmp: true
#Please make sure to fill out the below details if you have chosen to enable SNMP, leaving it empty will cause the setup to fail
snmp_contact: "Administrator"
snmp_location: "RTP"
traphost_ip: "10.61.185.58"
snmp_community: "FlexPod"

#SNMPv3 related variables
user: snmpv3_user   #The name of the user to manage
authentication_protocol: none   #Authentication protocol for the snmp user (Choices: none, md5, sha, sha2-256)
authentication_password: <enter password>   #Password for the authentication protocol
privacy_protocol: none   #Privacy protocol for the snmp user (Choices: none, des, aes128)
privacy_password: <enter password>   #Password for the privacy protocol

##################################################################################################################################################

ha_pairs:
  - ha_no: 1										
    node_port_count: "4"		
    node_data_ports: ["e0g","e0h"]
    node_fcp_ports: ["0g","0h"]
    fcp_port_speed: "8"
    node_specs:
    - node_name: node-01
      sp: {ip: 10.61.183.51, mask: 255.255.255.0, gateway: 10.61.183.1}
      node_mgmt_ip: 10.61.183.60
      partner_mgmt_ip: 10.61.183.61
      data_aggregates: 
        - {aggr_name: aggr01_node01, disk_type: SSD, diskcount: 5}  #Options for disk_type: SAS, SSD, SSD-NVM 
        - {aggr_name: aggr02_node01_nvme, disk_type: SSD-NVM, diskcount: 5}
      nfs_lifs: {name: nfs_lif01, address: 172.22.50.162, netmask: 255.255.255.0}  #Fill out this value only if nfs will be mentioned under allowed_protocols in svm_specs
      fcp_lifs:    #Fill out this value only if fcp will be mentioned under allowed_protocols in svm_specs
        - {name: fcp_lif01a, home_port: 0g, fabric: A}  #Do not change the fabric ID
        - {name: fcp_lif01b, home_port: 0h, fabric: B}  #Do not change the fabric ID
      fc-nvme_lifs:    #Fill out this value only if nvme will be mentioned under allowed_protocols in svm_specs
        - {name: fc-nvme-lif-01a, home_port: 5a, fabric: A}  #Do not change the fabric ID
        - {name: fc-nvme-lif-01b, home_port: 5b, fabric: B}  #Do not change the fabric ID
      iscsi_lifs:  #Fill out this value only if iscsi will be mentioned under allowed_protocols in svm_specs. Provide one iSCSI LIF per iSCSI VLAN
        - {name: iscsi_lif01a, address: 172.22.10.162, netmask: 255.255.255.0, fabric: A}  #Do not change the fabric ID
        - {name: iscsi_lif01b, address: 172.22.20.162, netmask: 255.255.255.0, fabric: B}  #Do not change the fabric ID
    - node_name: node-02
      sp: {ip: 10.61.183.52, mask: 255.255.255.0, gateway: 10.61.183.1}
      node_mgmt_ip: 10.61.183.61
      partner_mgmt_ip: 10.61.183.60
      data_aggregates: 
        - {aggr_name: aggr01_node02, disk_type: SSD, diskcount: 5}  #Options for disk_type: SAS, SSD, SSD-NVM 
        - {aggr_name: aggr02_node02_nvme, disk_type: SSD-NVM, diskcount: 5}      
      nfs_lifs: {name: nfs_lif02, address: 172.22.50.163, netmask: 255.255.255.0}  #Fill out this value only if nfs will be mentioned under allowed_protocols in svm_specs
      fcp_lifs:    #Fill out this value only if fcp will be mentioned under allowed_protocols in svm_specs
        - {name: fcp_lif02a, home_port: 0g, fabric: A}  #Do not change the fabric ID
        - {name: fcp_lif02b, home_port: 0h, fabric: B}  #Do not change the fabric ID
      fc-nvme_lifs:    #Fill out this value only if nvme will be mentioned under allowed_protocols in svm_specs
        - {name: fc-nvme-lif-02a, home_port: 5a, fabric: A}  #Do not change the fabric ID
        - {name: fc-nvme-lif-02b, home_port: 5b, fabric: B}  #Do not change the fabric ID
      iscsi_lifs:  #Fill out this value only if iscsi will be mentioned under allowed_protocols in svm_specs. Provide one iSCSI LIF per iSCSI VLAN
        - {name: iscsi_lif02a, address: 172.22.10.163, netmask: 255.255.255.0, fabric: A}  #Do not change the fabric ID
        - {name: iscsi_lif02b, address: 172.22.20.163, netmask: 255.255.255.0, fabric: B}  #Do not change the fabric ID
  - ha_no: 2
    node_port_count: "2"
    node_data_ports: ["e0c","e0d"]
    node_fcp_ports: ["0a","0b"]
    fcp_port_speed: "16"
    node_specs:
    - node_name: node-03
      sp: {ip: 10.61.183.53, mask: 255.255.255.0, gateway: 10.61.183.1}
      node_mgmt_ip: 10.61.183.62
      partner_mgmt_ip: 10.61.183.63
      data_aggregates: 
        - {aggr_name: aggr01_node03, disk_type: SSD, diskcount: 5}  #Options for disk_type: SAS, SSD, SSD-NVM
        - {aggr_name: aggr02_node03_nvme, disk_type: SSD-NVM, diskcount: 5} 
      nfs_lifs: {name: nfs_lif03, address: 172.22.50.164, netmask: 255.255.255.0}  #Fill out this value only if nfs will be mentioned under allowed_protocols in svm_specs
      fcp_lifs:    #Fill out this value only if fcp will be mentioned under allowed_protocols in svm_specs
        - {name: fcp_lif03a, home_port: 0a, fabric: A}  #Do not change the fabric ID
        - {name: fcp_lif03b, home_port: 0b, fabric: B}  #Do not change the fabric ID
      fc-nvme_lifs:    #Fill out this value only if nvme will be mentioned under allowed_protocols in svm_specs
        - {name: fc-nvme-lif-03a, home_port: 1a, fabric: A}  #Do not change the fabric ID
        - {name: fc-nvme-lif-03b, home_port: 1b, fabric: B}  #Do not change the fabric ID
      iscsi_lifs:  #Fill out this value only if iscsi will be mentioned under allowed_protocols in svm_specs. Provide one iSCSI LIF per iSCSI VLAN
        - {name: iscsi_lif03a, address: 172.22.10.164, netmask: 255.255.255.0, fabric: A}  #Do not change the fabric ID
        - {name: iscsi_lif03b, address: 172.22.20.164, netmask: 255.255.255.0, fabric: B}  #Do not change the fabric ID
    - node_name: node-04
      sp: {ip: 10.61.183.54, mask: 255.255.255.0, gateway: 10.61.183.1}
      node_mgmt_ip: 10.61.183.63
      partner_mgmt_ip: 10.61.183.62
      data_aggregates: 
        - {aggr_name: aggr01_node04, disk_type: SSD, diskcount: 5}  #Options for disk_type: SAS, SSD, SSD-NVM
        - {aggr_name: aggr02_node04_nvme, disk_type: SSD-NVM, diskcount: 5} 
      nfs_lifs: {name: nfs_lif04, address: 172.22.50.165, netmask: 255.255.255.0}  #Fill out this value only if nfs will be mentioned under allowed_protocols in svm_specs
      fcp_lifs:    #Fill out this value only if fcp will be mentioned under allowed_protocols in svm_specs                              
        - {name: fcp_lif04a, home_port: 0a, fabric: A}  #Do not change the fabric ID
        - {name: fcp_lif04b, home_port: 0b, fabric: B}  #Do not change the fabric ID
      fc-nvme_lifs:    #Fill out this value only if nvme will be mentioned under allowed_protocols in svm_specs
        - {name: fc-nvme-lif-04a, home_port: 1a, fabric: A}  #Do not change the fabric ID
        - {name: fc-nvme-lif-04b, home_port: 1b, fabric: B}  #Do not change the fabric ID
      iscsi_lifs:  #Fill out this value only if iscsi will be mentioned under allowed_protocols in svm_specs. Provide one iSCSI LIF per iSCSI VLAN
        - {name: iscsi_lif04a, address: 172.22.10.165, netmask: 255.255.255.0, fabric: A}  #Do not change the fabric ID
        - {name: iscsi_lif04b, address: 172.22.20.165, netmask: 255.255.255.0, fabric: B}  #Do not change the fabric ID

##################################################################################################################################################
#SVM specific variables
##################################################################################################################################################

svm_specs:
  svm_name: infra_svm
  svm_root_vol: infra_root
  allowed_protocols:
    - nfs
    - fcp
    - nvme
  client_match: 172.21.246.0/24
  data_protocol: nfs
  data_volumes:
    - {name: infra_datastore1, size: 500, residing_aggr: aggr01_node01}
    - {name: infra_datastore2, size: 100, residing_aggr: aggr01_node03}
  swap_volumes:
    - {name: infra_swap, size: 200, residing_aggr: aggr01_node01}
  nvme_datastores:
    - {name: NVMe_datastore_01, size: 200, residing_aggr: aggr02_node01_nvme} #Use the data aggregates with disk_type as SSD-NVM
    - {name: NVMe_datastore_02, size: 100, residing_aggr: aggr02_node03_nvme}   
  data_luns:
  boot_volumes:
    - {name: esxi_boot, size: 200, residing_aggr: aggr01_node02}
  boot_luns:
    - {name: VM-Host-Infra-01, size: 15, residing_vol: esxi_boot}
    - {name: VM-Host-Infra-02, size: 15, residing_vol: esxi_boot}
  nvme_namespace:
    - {name: NVMe_namespace_01, size: 50, residing_vol: NVMe_datastore_01}  #Use NVMe datastore as residing volume here
    - {name: NVMe_namespace_02, size: 50, residing_vol: NVMe_datastore_02}  #Enter size values in gb
  nvme_subsystem:
    - {name: nvme_infra_host_01, nqn: ["nqn.1992-08.com.netapp:sn.e01bbb1de4f911ebac6fd039ea166b8c:subsystem.nvme_infra_host_01"]}  #Obtain the NQN from the host
    - {name: nvme_infra_host_02, nqn: ["nqn.1992-08.com.netapp:sn.e01bbb1de4f911ebac6fd039ea166b8c:subsystem.nvme_infra_host_02"]}
  iscsi_igroups:
    - {name: VM-Host-Infra-01-ISCSI, iqn: ["iqn.1992-08.com.cisco:ucs-host:1"]}
    - {name: VM-Host-Infra-02-ISCSI, iqn: ["iqn.1992-08.com.cisco:ucs-host:2"]}
  fcp_igroups:
    - {name: VM-Host-Infra-01-FCP, wwpn: ["20:00:00:25:B5:32:0A:00","20:00:00:25:B5:32:0B:00"]}
    - {name: VM-Host-Infra-02-FCP, wwpn: ["20:00:00:25:B5:32:0A:01","20:00:00:25:B5:32:0B:01"]}
  svm_mgmt_lif: {home_node: node-01, home_port: e0M, address: 10.61.181.254, netmask: 255.255.255.0, gateway: 10.61.181.1, lif_name: infra_svm_mgmt}
  vsadmin_password: NetApp!23
  os_type: vmware
  dns_server_svm:
    - 10.61.184.251
    - 10.61.184.252
  dns_domain_svm: "cie.netapp.com"

##################################################################################################################################################
# Default/Best Practice related information - Change only if required
##################################################################################################################################################

#Following variable is used in a task to ensure auto revert for cluster management LIF is set to True.
cluster_mgmt_auto_revert: true

#Name of the Interface group to be created
ifgrp_name: a0a

ifgrp_mode: multimode_lacp

#Job Schedule
job_schedule:
  - {job_name: 15min,job_minutes: 15}
